<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arti Voice Assistant</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        h1 { margin: 20px 0; font-size: 28px; }
        .container {
            max-width: 600px;
            width: 100%;
            background: rgba(255,255,255,0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
        }
        .status {
            text-align: center;
            padding: 20px;
            border-radius: 15px;
            margin: 20px 0;
            font-size: 18px;
            transition: all 0.3s;
        }
        .status.listening { background: rgba(0,255,0,0.2); border: 2px solid #00ff00; }
        .status.wake { background: rgba(255,165,0,0.2); border: 2px solid #ffa500; }
        .status.processing { background: rgba(0,165,255,0.2); border: 2px solid #00a5ff; }
        .status.speaking { background: rgba(255,0,255,0.2); border: 2px solid #ff00ff; }
        .status.error { background: rgba(255,0,0,0.2); border: 2px solid #ff0000; }
        .mic-btn {
            display: block;
            margin: 30px auto;
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(145deg, #2a2a4a, #1a1a2e);
            cursor: pointer;
            transition: all 0.3s;
            font-size: 40px;
        }
        .mic-btn:hover { transform: scale(1.05); }
        .mic-btn.active { background: linear-gradient(145deg, #00ff00, #00aa00); }
        .mic-btn.wake { background: linear-gradient(145deg, #ffa500, #ff6600); animation: pulse 1s infinite; }
        @keyframes pulse { 0%,100% { box-shadow: 0 0 0 0 rgba(255,165,0,0.5); } 50% { box-shadow: 0 0 0 20px rgba(255,165,0,0); } }
        .conversation {
            background: rgba(0,0,0,0.3);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            max-height: 300px;
            overflow-y: auto;
        }
        .message { margin: 10px 0; padding: 10px 15px; border-radius: 10px; }
        .message.user { background: rgba(0,150,255,0.2); margin-left: 20%; }
        .message.arti { background: rgba(0,255,0,0.2); margin-right: 20%; }
        .log {
            font-family: monospace;
            font-size: 12px;
            opacity: 0.7;
            padding: 10px;
            background: rgba(0,0,0,0.3);
            border-radius: 10px;
            margin-top: 20px;
            max-height: 150px;
            overflow-y: auto;
        }
        .config {
            display: grid;
            gap: 10px;
            margin: 20px 0;
        }
        .config label { display: block; margin-bottom: 5px; font-size: 14px; opacity: 0.8; }
        .config input {
            width: 100%;
            padding: 10px;
            border: none;
            border-radius: 8px;
            background: rgba(255,255,255,0.1);
            color: #fff;
            font-size: 14px;
        }
        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s;
        }
        .btn-primary { background: linear-gradient(145deg, #00a5ff, #0066aa); color: #fff; }
        .btn-secondary { background: rgba(255,255,255,0.1); color: #fff; }
        .btn:hover { transform: translateY(-2px); }
    </style>
</head>
<body>
    <h1>ðŸŽ¤ Arti Voice Assistant</h1>
    
    <div class="container">
        <div class="config">
            <label>OpenClaw Gateway URL</label>
            <input type="text" id="gatewayUrl" value="ws://127.0.0.1:18789">
            <label>OpenClaw Token (optional)</label>
            <input type="password" id="gatewayToken" placeholder="Enter token if required">
        </div>
        
        <button class="btn btn-primary" id="startBtn">Start Listening</button>
        
        <div class="status" id="status">Click "Start Listening" to begin</div>
        
        <button class="mic-btn" id="micBtn" disabled>ðŸŽ¤</button>
        
        <div class="conversation" id="conversation">
            <div class="message arti">ðŸ‘‹ Hello! Say "Hey Arti" to wake me up, then speak your question.</div>
        </div>
        
        <div class="log" id="log"></div>
    </div>

    <script>
        // Configuration
        let gatewayUrl = 'ws://127.0.0.1:18789';
        let gatewayToken = '';
        let isListening = false;
        let isProcessing = false;
        let wakeWordActive = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let recognition = null;
        let synthesis = window.speechSynthesis;
        let ws = null;
        
        // DOM elements
        const startBtn = document.getElementById('startBtn');
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        const conversation = document.getElementById('conversation');
        const log = document.getElementById('log');
        const gatewayUrlInput = document.getElementById('gatewayUrl');
        const gatewayTokenInput = document.getElementById('gatewayToken');
        
        function addLog(msg) {
            const time = new Date().toLocaleTimeString();
            log.innerHTML = `[${time}] ${msg}\n` + log.innerHTML;
        }
        
        function addMessage(text, isUser) {
            const div = document.createElement('div');
            div.className = `message ${isUser ? 'user' : 'arti'}`;
            div.textContent = (isUser ? 'ðŸ‘¤ You: ' : 'ðŸŽ¤ Arti: ') + text;
            conversation.appendChild(div);
            conversation.scrollTop = conversation.scrollHeight;
        }
        
        function setStatus(text, className = '') {
            status.textContent = text;
            status.className = 'status ' + className;
        }
        
        function speak(text) {
            setStatus('Speaking...', 'speaking');
            addLog('Speaking: ' + text.substring(0, 50) + '...');
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 1.0;
            utterance.pitch = 1.0;
            utterance.onend = () => {
                addLog('Speech complete');
                if (wakeWordActive) {
                    setStatus('Listening for "Hey Arti"...', 'listening');
                } else {
                    setStatus('Say "Hey Arti" to wake me', '');
                }
            };
            utterance.onerror = (e) => {
                addLog('Speech error: ' + e.error);
                setStatus('Error speaking', 'error');
            };
            synthesis.speak(utterance);
        }
        
        async function sendToAgent(message) {
            addLog('Sending to agent: ' + message);
            setStatus('Thinking...', 'processing');
            
            try {
                // Connect to OpenClaw gateway
                ws = new WebSocket(gatewayUrl);
                
                ws.onopen = () => {
                    addLog('Connected to OpenClaw');
                    ws.send(JSON.stringify({
                        type: 'agent.turn',
                        message: message
                    }));
                };
                
                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    addLog('Response received');
                    
                    if (data.message) {
                        addMessage(data.message, false);
                        speak(data.message);
                    } else if (data.text) {
                        addMessage(data.text, false);
                        speak(data.text);
                    }
                    
                    ws.close();
                };
                
                ws.onerror = (e) => {
                    addLog('WebSocket error');
                    setStatus('Connection error', 'error');
                };
                
                ws.onclose = () => {
                    addLog('Disconnected from OpenClaw');
                };
                
            } catch (e) {
                addLog('Error: ' + e.message);
                setStatus('Error connecting to agent', 'error');
                addMessage('Sorry, I couldn\'t reach the agent.', false);
            }
        }
        
        async function recordAndSend() {
            try {
                setStatus('Listening...', 'wake');
                addLog('Starting recording');
                
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (e) => {
                    audioChunks.push(e.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    addLog('Recording stopped, processing...');
                    
                    // Transcribe using Web Speech API
                    if (recognition) {
                        recognition.start();
                        
                        recognition.onresult = (event) => {
                            const transcript = event.results[0][0].transcript;
                            addLog('Transcribed: ' + transcript);
                            
                            if (transcript.toLowerCase().includes('hey arti') || transcript.toLowerCase().includes('hey arty')) {
                                addLog('Wake word detected!');
                                wakeWordActive = true;
                                speak('Yes? How can I help you?');
                            } else {
                                addMessage(transcript, true);
                                sendToAgent(transcript);
                            }
                        };
                        
                        recognition.onerror = (e) => {
                            addLog('Speech recognition error: ' + e.error);
                        };
                    }
                };
                
                mediaRecorder.start();
                
                // Record for 5 seconds max
                setTimeout(() => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        stream.getTracks().forEach(track => track.stop());
                    }
                }, 5000);
                
            } catch (e) {
                addLog('Microphone error: ' + e.message);
                setStatus('Microphone access denied', 'error');
            }
        }
        
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';
                addLog('Speech recognition initialized');
            } else {
                addLog('Speech recognition not supported');
                setStatus('Speech recognition not supported', 'error');
            }
        }
        
        function start() {
            gatewayUrl = gatewayUrlInput.value || 'ws://127.0.0.1:18789';
            gatewayToken = gatewayTokenInput.value;
            
            addLog('Starting Arti Voice Assistant...');
            addLog('Gateway URL: ' + gatewayUrl);
            
            isListening = true;
            wakeWordActive = false;
            startBtn.disabled = true;
            startBtn.textContent = 'Listening...';
            micBtn.disabled = false;
            
            initSpeechRecognition();
            
            // Continuous wake word detection loop
            async function listenLoop() {
                while (isListening) {
                    if (!wakeWordActive && !isProcessing) {
                        await recordAndSend();
                    }
                    await new Promise(r => setTimeout(r, 100));
                }
            }
            listenLoop();
            
            setStatus('Say "Hey Arti" to wake me', 'listening');
            addLog('Listening for wake word...');
        }
        
        startBtn.onclick = start;
        
        // Log browser info
        addLog('User Agent: ' + navigator.userAgent.substring(0, 50) + '...');
        addLog('SpeechSynthesis available: ' + (synthesis ? 'yes' : 'no'));
        addLog('SpeechRecognition available: ' + ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window ? 'yes' : 'no'));
    </script>
</body>
</html>
